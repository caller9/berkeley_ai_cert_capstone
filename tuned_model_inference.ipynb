{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c7cf74-1153-4dff-9ff9-fcb215c83b4d",
   "metadata": {},
   "source": [
    "# Test inference on the fine-tuned, merged model.\n",
    "\n",
    "This notebook requires that you have first run the `fine_tune.ipynb` notebook to generate the `merged-fine-tuned` model and tokenizer. This will load the new model and run inference a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20be6861-460c-4b21-86c4-5da216c29744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d17cc09-1a98-44b8-b077-e47cc79cdc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model_dir = \"merged-fine-tuned\"\n",
    "#merged_model_dir = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76064767-548e-4774-94e6-0039be93c1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769e96900086460e92c6aafa20d597bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_model = AutoModelForCausalLM.from_pretrained(\n",
    "    merged_model_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(merged_model_dir)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b05e75d-c2ac-439b-9ce5-9dfd903d27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_model(msg):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": msg},\n",
    "    ]\n",
    "    \n",
    "    encoded = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    generated_ids = merged_model.generate(encoded, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id, no_repeat_ngram_size = 6, temperature=0.9)\n",
    "    decoded = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    return decoded\n",
    "\n",
    "def send_chat(msg):\n",
    "    result = send_to_model(msg)[0]\n",
    "    return result.rsplit(\" [/INST] \", 1)[1]\n",
    "\n",
    "def print_chat(msg):\n",
    "    print(send_chat(msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea32d598-c8d3-413b-a839-b1870938019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open the file in Python and use this code: \n",
      "\n",
      "```\n",
      "with open('file.txt', 'r') as f:\n",
      "    contents = f.read()\n",
      "```\n",
      "\n",
      "Replace `'file.txt'` with the name of your text file. The `'r'` mode opens the file in read mode and the `f.read()` function reads the entire contents into a string.\n"
     ]
    }
   ],
   "source": [
    "print_chat(\"How much wood would a woodchuck chuck if a woodchuck could chuck wood?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e967f02-c578-46e8-b27b-5fe53ae2803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make a bulleted list at the beginning of a line in markdown, optionally indent the line then use an asterisk at the beginning of each line. Example:\n",
      "* First list item \n",
      "* Second list item \n",
      "* Third list item \n",
      "  * Sub item under third item \n",
      "  * Another sub item under third item \n"
     ]
    }
   ],
   "source": [
    "print_chat(\"How do I make a bulleted list in markdown?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6f48f8a-d33b-4a1b-b344-28f6b24d061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an AI language model, so I don't have feelings or physical sensations. However, I'm here to help you with any questions or tasks you have! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print_chat(\"How are you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00473161-8009-4271-a9ad-e74274bca3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have personal preferences or favorites. I'm here to help you find information. What magazine are you looking for?\n"
     ]
    }
   ],
   "source": [
    "print_chat(\"What is your favorite magazine?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b771ce4-674b-44fc-a739-10e93db87012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. You start with 3 plates. \n",
      "2. Then you use one of the plates to eat your food.\n",
      "3. Since you're done eating and you don't need the used plate anymore, you can set it aside. \n",
      "4. So, even though you used one of the plates, you still have the other two with you. \n",
      "\n",
      "Therefore, you would have 2 plates left.\n"
     ]
    }
   ],
   "source": [
    "print_chat(\"If you hade 3 plates and you ate off of one of them, how many plates would you have left? Explain it step by step.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cc7afce-f57d-41ba-9edb-1c61fc1a7c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACME in partnership with Wizbarg ISD has announced that school pick-up for Boba Fett and Ashoka Tano schools must utilize the designated school pick-up lines starting from now on. This is to ensure the safety of students after school. The sheriff's office will be at ACME for the next two weeks to redirect traffic and hand out citations for those who violate the rules. Any inquiries should be directed to roundfile@localhost or school administration. ACME thanks everyone for their cooperation with this safety initiative.\n"
     ]
    }
   ],
   "source": [
    "document = \"\"\"\n",
    "Good evening to everyone,\n",
    "\n",
    "In partnership with Wizbang ISD, ACME will be requiring that school pick-up traffic for Boba Fett Elementary and Ashoka Tano Middle School utilize the school pick up lines going forward and cease using the ACME parking lot for pick-up in any capacity. This is to ensure that District approved pick-up safety plans are followed and provides the safest avenue for student pick-up after school. The Mos Eisley County Sheriff's Office will be on-site for the next two weeks at ACME to redirect all traffic relating to school pick-ups to the appropriate school pick-up line as well as will be giving out citations for standing in designated No Parking zones or sitting on the curb where standing is not allowed.\n",
    "\n",
    "Should you have any questions, please email us at roundfile@localhost, or contact school administration.\n",
    "\n",
    "Thank you and we appreciate everyone's cooperation with this safety initiative,\n",
    "\n",
    "ACME Management\n",
    "\"\"\"\n",
    "\n",
    "print_chat(f\"Summarize: {document}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352823a-8d87-4c84-81f8-ab1e20af4001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
