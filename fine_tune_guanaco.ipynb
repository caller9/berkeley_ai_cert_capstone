{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b552ec9b-0233-4003-ab85-8f2a6fcd4b91",
   "metadata": {},
   "source": [
    "# Convert and save a subset of the guanaco instruction fine tuning data \n",
    "\n",
    "I downloaded the Guanaco fine tuning dataset https://huggingface.co/datasets/timdettmers/openassistant-guanaco. Then I save a subset of training data that is under a binary searched token size limit that won't cause an out of memory error when training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627f9b2c-d3b8-40cb-9ff9-28fd9c918fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "182fae00-74c9-4317-a5b2-20ae0b050c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "guanaco = load_dataset('timdettmers/openassistant-guanaco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ba3a36-2101-4129-82ca-3779d6e8fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = guanaco['train']\n",
    "training_df = training_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44a3b54-d2eb-4c06-b086-a621d78d1aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9846 entries, 0 to 9845\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    9846 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 77.1+ KB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60013ec5-ef7c-4637-8831-89b71e9ee35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>### Human: hola### Assistant: Hola, ¿Qué tal e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>### Human: ¿Cómo puedo hablarle a la chica que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9660</th>\n",
       "      <td>### Human: Write a python code that lists all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7359</th>\n",
       "      <td>### Human: Crea una pregunta de examen de alge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7332</th>\n",
       "      <td>### Human: What date will the united states ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>### Human: Как защитить линукс систему?### Ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>### Human: ¿Cuáles son los principales problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>### Human: 摩托没有后 abs 安全么？### Assistant: ABS （a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6116</th>\n",
       "      <td>### Human: Nombrame todas las capitales del mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>### Human: ¿Qué películas de terror que este e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "2310  ### Human: hola### Assistant: Hola, ¿Qué tal e...\n",
       "3130  ### Human: ¿Cómo puedo hablarle a la chica que...\n",
       "9660  ### Human: Write a python code that lists all ...\n",
       "7359  ### Human: Crea una pregunta de examen de alge...\n",
       "7332  ### Human: What date will the united states ec...\n",
       "1620  ### Human: Как защитить линукс систему?### Ass...\n",
       "4952  ### Human: ¿Cuáles son los principales problem...\n",
       "3431  ### Human: 摩托没有后 abs 安全么？### Assistant: ABS （a...\n",
       "6116  ### Human: Nombrame todas las capitales del mu...\n",
       "624   ### Human: ¿Qué películas de terror que este e..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365ae0ac-3937-4386-b610-973fa6d42216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the whole training set, you may wish to use a smaller sample to experiment.\n",
    "sample_subset = training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2981890-6b32-48f6-9bb9-1bed8cde66d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e63088b-0ae5-4167-a0c1-49b857ad84d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 8679 entries\n"
     ]
    }
   ],
   "source": [
    "# Limit the size of the inputs to a specified amount of tokens. \n",
    "# Otherwise we'll get out of memory errors during training.\n",
    "token_size_limit = 800\n",
    "\n",
    "# Prevent reserved strings used by the model from appearing in the traning data itself.\n",
    "reserved_strings = [\"[INST]\", \"[/INST]\", \"<s>\", \"</s>\"]\n",
    "\n",
    "# Convert to format expected by Mistral \"<s> [INST] User Instruction [/INST] Response </s>\"\n",
    "# Use the tokenizer itself to apply the chat template and avoid manual string concatenation.\n",
    "def convert_convo(messages):\n",
    "    encoded = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")[0]\n",
    "    return len(encoded), tokenizer.decode(encoded)\n",
    "\n",
    "def convert_entry(entry):\n",
    "    messages = []\n",
    "\n",
    "    # Reject any entries that contain existing Mistral instruction format markers\n",
    "    if any(reserved in entry for reserved in reserved_strings):\n",
    "        return 0, None\n",
    "\n",
    "    # Reject entries with conversation chains that are too long\n",
    "    segments = entry.split('### Human:')\n",
    "\n",
    "    # For each human -> assistant exchange, append to a list in Mistral format\n",
    "    for segment in segments:\n",
    "        convo_split = segment.split('### Assistant:')\n",
    "        human = convo_split[0].strip()\n",
    "        if len(human) == 0:\n",
    "            continue\n",
    "        messages.append({\"role\": \"user\", \"content\": human})\n",
    "        assistant = \"\"\n",
    "        if (len(convo_split) > 1):\n",
    "            assistant = convo_split[1].strip()\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "\n",
    "    # Convert the list of user and assistant messages to Mistral format.\n",
    "    token_size, mistral_convo = convert_convo(messages)\n",
    "        \n",
    "    # Return a map (JSON object) with the text for training\n",
    "    return token_size, {'text': mistral_convo}\n",
    "\n",
    "training_entries = []\n",
    "for index, entry in sample_subset.iterrows():\n",
    "    token_size, converted_entry = convert_entry(entry['text'])\n",
    "    if converted_entry and token_size <= token_size_limit:\n",
    "        training_entries.append(converted_entry)\n",
    "\n",
    "# Write all of the data to JSONL file\n",
    "with open(\"data/fine_tune.jsonl\", 'w') as f:\n",
    "    print(f\"Saving {len(training_entries)} entries\")\n",
    "    for training_entry in training_entries:\n",
    "        f.write(json.dumps(training_entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486e901-9374-44ed-a11c-221ca71d1ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
