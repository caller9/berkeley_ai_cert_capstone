{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da28ba98-c899-441a-9ea6-a78a7c7c9716",
   "metadata": {},
   "source": [
    "# Retrieval augmented chat - Mistral-7B locally fine tuned\n",
    "\n",
    "This notebook is the primary demonstration of the project with the fine tuned model based on the untuned Mistral-7B model. Here we'll bring up the locally fine tuned model and vector database and start asking questions both with and without the vector database. This notebook requires that you have first run the `fine_tune.ipynb` notebook to generate the `merged-fine-tuned` model and tokenizer. This will load the new model and run inference a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea286197-5a87-4f1b-abc3-bef2298a37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99fd829-3019-4de8-b27c-947c8a7f2d9b",
   "metadata": {},
   "source": [
    "## Initialize some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a05ed5f-66ef-4cc5-9813-736405bdefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"Corpus\"\n",
    "model_dir = \"merged-fine-tuned\"\n",
    "device_map = {\"\": 0}\n",
    "device = \"cuda\"\n",
    "database_top_n_results = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a299a70-0e8f-4947-b8a5-af2b37a32bc3",
   "metadata": {},
   "source": [
    "## Load shared code\n",
    "This file defines the `ChatModel` and `Retrieval` classes used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0127f1-910c-49b6-9210-97d8b68ef671",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run shared_code.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde5370-9aa9-4138-8e0e-a52e17c0f6db",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a41d92-5a28-4668-8e8b-2f37bf0180e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124e220a38bc4720bbb4d1cf8c895e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "language_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10163ab3-e55c-403b-96f9-7d0d338cb18c",
   "metadata": {},
   "source": [
    "## Load the model into the ChatModel class from `shared_code.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064cd72c-2f70-49b6-8862-30d56ec9d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatModel(language_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c18cc-2fd8-46b5-a107-1d21c494187a",
   "metadata": {},
   "source": [
    "## Trying the model without access to the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551660eb-3f81-434e-8029-f0babd9b7969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several ways to loop a GIF:\n",
      "\n",
      "1. Using JavaScript: You can use JavaScript to create an infinite loop that plays the GIF repeatedly using this code: function playGif() {  var image = new Image(); // Create a new image object  image.src = 'path_to_the_GIF.jpg'; // Set the source of the image  image.play(0, false, false); // Begin playing the GIF repeatedly }; playGif(); // Call the function to start the loop 2. Using Python: If you're working with Python, there is another way to achieve the same result by creating a new animation object and then adding the GIF as its first frame using this code: from PIL import Image, Animation, AnimatedImageSourceInfo, AnimationObject, ExpertException, ImageListError, MappedImage, CompositeOp, TransitionEffect, Dimensions, ScaleFactor, BoundingBox, Layer, RenderFlag, Keycode, Colormap, FontType, Fps, Raster, PaletteType \n",
      "def __init__(self): # Initialize the animator objects self.__animator = AnimationObject('simple') self.timeline = ['0', 0.0, (self._width, self._height)] # Animation parameters for width x height viewport else: self.framecount = 0 self.totalFrameCount = len(self) # Store each frame's position in memory\n",
      "        while True: # Loop through frames forever if self.__animator.isMovie(): super().__init__() super().run()    except Exception as e: print(\"An exception occurred:\", e)     try:       self.update()   except Exception as e: print(\"An exception occurred:\", e)  finally: pass                                      self.draw_frame()\n",
      "        try:\n",
      "            self.getextended_size()\n",
      "        except:\n",
      "            raise AttributeError()\n",
      "    def getextended_image(self):\n",
      "        img = self.__img\n",
      "        if not img or img.isAlpha:\n",
      "            raise KeyboardInterrupt(\n",
      "                f\"The original size does not support alpha: \"\n",
      "                , self.__keyCode)\n",
      "        bbox = self.bbox.getExtent()\n",
      "        extrema = bbox.min[2, 3] + bbox.max[2, 3]\n",
      "        size = ((int, int), extrema)\n",
      "        pix = img.convertTuplePixels((int, int))\n",
      "        return ImageComposite(\n",
      "            *self.fontlist, (0, pix), size, \n",
      "            CompositeOp.MODE_OVERLAY, (Keycode('M'), Keycode('PAINT'))\n",
      "        )\n",
      "    def draw_frame(self):\n",
      "        pyx = self.renderer.context\n",
      "        # Unlock the GPU for composited images\n",
      "        try:\n",
      "            self.pyx.fx.unlock()\n",
      "            super().draw_rect(\n",
      "                (self.pos[0], self.pos[1])[:2],\n",
      "                self.draw_mask(self).bind())\n",
      "        except:\n",
      "            if self.__error:\n",
      "                super().draw_rect(*self.__error, :2), super().fps\n",
      "                raise self.__exception\n",
      "        elif self.rendering.isEllipse():\n",
      "            self.render_ellipses([self.pos[0]])\n",
      "        elif self.rendering.isPointLight():\n",
      "            self.render_points()\n",
      "            self.clipping = PyXCCState(self, False)\n",
      "        else: # Compute new clipping based on the current viewpoint\n",
      "            self.clipping = PyXCCState(\n",
      "                self, getattr(self.rendering, ('viewport')))\n",
      "        \n",
      "        imgp = self.getextended_image()\n",
      "        hls = self.handlerlists[2][3]\n",
      "        self.renderer.ctx.blitW(imgp, hls)\n",
      "        self.renderer.fps\n",
      "    except Keycode:\n",
      "        # The keycode could be invalid / unsupported causing issues when rendering.\n",
      "        self.kill_animation()\n",
      "        self.clear_cache() \n",
      "        raise KVHException(u\"Invalid Keycode:\")\n",
      "    except:\n",
      "        self.kill_animation()\n",
      "        self.clear_cache()\n",
      "        raise self.__exception  # The catch block will only execute once if the excepted Exception. is valid.\n",
      "    main = self.interpreter.main()\n"
     ]
    }
   ],
   "source": [
    "chat_model.basic_chat(\"How do I loop a GIF?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035b376-3b51-4da9-a4fd-23f2a7d2f5fc",
   "metadata": {},
   "source": [
    "## Load the collection into the RetrievalAugmentedChat class from `shared_code.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7888382-4a37-4612-b7ef-3fa2a132d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rac = RetrievalAugmentedChat(\"db/\", collection_name, database_top_n_results, chat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8476ee89-d947-44e2-9c82-6797396cd3b2",
   "metadata": {},
   "source": [
    "## Run retrieval augmented chat\n",
    "Notice that the responses have switched from a general HTML/JavaScript context to include the document contents which provide examples of encoding the gif with ImageMagick so that it loops by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b0024a-5c2d-42bf-bbba-3533b3cf2fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To run a GIF repeatedly using ImageMagick, follow these steps:\n",
       "\n",
       "1. Create a new directory for the image files, e.g., /home/$USER/.compiled_pics/GIFS:\n",
       "\n",
       "mkdir ~/.compiled_pics.git\n",
       "cd .compiled_pictures.git\n",
       "cp *.[^.jpg.* ^^*.png {2,3} ./Cached_Images/* && rm -rf Cached_Images\n",
       "\n",
       "The above commands set up the Compiled Pics directory, copies all JPG, PNG, and raw images into, and removes the temporary cache folder containing the source images. This enables us to run the following command multiple times without needing to rerun each time.\n",
       "\n",
       "2. Install Imagemagik: The below code installs Imagemagic in the system based directories, allowing other tools such as mogrify to access imagedigits features. Note that it may require sudo privileges to complete due to ownership permissions errors. We are using the current version due to the release date.\n",
       "\n",
       "$ sudo apt-get install build-essential\n",
       "apt-get install imagemagick\n",
       "sudo apt-get install build-source\n",
       "sudo apt-get install xbuild-src\n",
       "sudo apt-get install libaio-1.01\n",
       "bash /usr/share/bin/install-rebuild\n",
       "3. Convert the image to a GIF: Before converting our image to a GIF we need to ensure it supports animations. The below command checks whether the input image has been built from another image. It does this by checking if any EXPLORER and ANIME segments exist. If they don’t then it is likely we only have one frame, i.e., the initial picture. In the case where this is true, we will simply loop the image in place to get a looping GIF. However, if there are multiple frames then we will apply animation, giving us a looping GIF.\n",
       "\n",
       "python convert.py \"input.jpg[0..int(framecount)]\" -out my_animated_drawing.gif > /dev/null\n",
       "\n",
       "In the above Python script, replace “my_animated_drawing.gif” with the path to your new GIF. The above function takes no arguments apart from possible image name but passing None is safe as Imagemagick will simply check the input file doesn’t change during processing. As mentioned previously, we now process a single frame. Let’s assume this is frame 0; assuming this is the case we loop by calling int() i.e., making sure the frame count = 1 and making sure our frame index i=index it becomes 10 as follows:\n",
       "for i in range(10): # Loop through all frames…\n",
       "while True:   # Run until frame loops    \n",
       "        try:          \n",
       "                magick_background=\"background.jpg[int(i)+256x256]\";\n",
       "            magick_foreground=\"foreground.jpg[int(i)+256x256]\";\n",
       "        magick, layers = self.magick.newacquire('mydrawing.gif[0], background', 'foreground')\n",
       "        \n",
       "       if not mw :break; \n",
       "        break;\n",
       "\n",
       "The above code creates two additional Magick objects representing the Background layer and Foreground layer. We’ve named them ‘background.jpg’, ‘foreground.jpg’. By adding +256x256 to both, we’re increasing their pixel dimensions by 256 pixels square. Which gives them smoother looking pixel art compared to default resolution images as well. Lastly, we feed the values into the MAGICK object. Because this could throw an exception about something our MAGECK can fail on (if it isn’t present), we’ll deal with failures gracefully in the except block. Assuming that everything works, it should render, then sleep for a bit to allow user to interact with the window before closing. Thus ending the infinite loop. Failing on either line will cause the Magic Object to close (assuming we have permission to kill Magick instance which might happen if it is running as root or if we haven’t root privileges). Rendering alone would just render with either one or none of the two foreground objects depending on what is applicable. Finally, we save as a GIF file and Print again stating where the GIF is located and that we exited successfully.\n",
       "\n",
       "Now you should be able to run the compilation scripts multiple times without side effects! \n",
       "\n",
       "Does this help answer\n",
       "\n",
       " **Reference documents:** \n",
       "\n",
       "* [corpus/imagemagick/set-a-gif-to-loop.md](corpus/imagemagick/set-a-gif-to-loop.md) distance: 0.97\n",
       "* [corpus/imagemagick/compress-animated-gif.md](corpus/imagemagick/compress-animated-gif.md) distance: 1.28\n",
       "\n",
       "**Inference time in seconds 20.3704**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rac.markdown_chat(\"How do I loop a GIF?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd178ea-8f8d-4a0f-a4ce-9bcde8dffd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "  **Can I use npm with GitHub actions?**\n",
       "\n",
       "- To achieve these goals you first need to determine what features your project has, for instance adding a .gitlab or .travis-ci configuration file as part of your deploy pipeline\n",
       "- Then you'll find yourself wanting several git-based resources such as commits, branches, compiles, upload archives etc\n",
       "- You'll notice there exists several different api endpoints throughout gitlab allowing each of these operations, including: list commits, create commit, delete branch, merge commit, push commit... etc\n",
       "- So to put all of that into some form to match your requirement you'll notice there exist several similarities among them where for instance you can use list commits without having to do commit history or list branches ending up with a similar result as if you were doing commit history\n",
       "- Note also that npm is notoriously unable to deal with asynchronous HTTP requests, however gitlab does support async operations\n",
       "\n",
       "So i will go ahead and assume you care about using npx as much as possible:\n",
       "\n",
       "---\n",
       "### Getting Gitlab urls via NPX\n",
       "#### Gitlab CLI URL Builder\n",
       "First, you need to install the GitLab Command Line Interface cli by running:\n",
       "> $ sudo apt-get add-source gitlab-cli\n",
       "> $ gitlab ci --version\n",
       "> $ gitlab clone --skip-update\n",
       "...\n",
       "Now if all succeeds you should see some output that looks likes this:\n",
       "> vstools gitlab ci--version 1.14.5\n",
       "> vstools gitlab clone --skip-update\n",
       "> +------------------+---------+--------------+\n",
       ">  |                 |         |             |\n",
       ">  <----->      ------->     --->-------\n",
       ">  \\--------------------------  -----------\n",
       ">  |   /           |                   |\n",
       ">  |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "\n",
       " **Reference documents:** \n",
       "\n",
       "* [corpus/github-actions/npm-cache-with-npx-no-package.md](corpus/github-actions/npm-cache-with-npx-no-package.md) distance: 0.88\n",
       "* [corpus/github-actions/attach-generated-file-to-release.md](corpus/github-actions/attach-generated-file-to-release.md) distance: 1.11\n",
       "\n",
       "**Inference time in seconds 20.2783**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rac.markdown_chat(\"Can I use npx with GitHub actions?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3ed6c-25c5-43b4-a3fb-b7dc52dba8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
