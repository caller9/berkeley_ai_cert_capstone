{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da28ba98-c899-441a-9ea6-a78a7c7c9716",
   "metadata": {},
   "source": [
    "# Retrieval augmented chat - Mistral-7B locally fine tuned\n",
    "\n",
    "This notebook is the primary demonstration of the project with the fine tuned model based on the untuned Mistral-7B model. Here we'll bring up the locally fine tuned model and vector database and start asking questions both with and without the vector database. This notebook requires that you have first run the `fine_tune.ipynb` notebook to generate the `merged-fine-tuned` model and tokenizer. This will load the new model and run inference a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea286197-5a87-4f1b-abc3-bef2298a37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99fd829-3019-4de8-b27c-947c8a7f2d9b",
   "metadata": {},
   "source": [
    "## Initialize some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a05ed5f-66ef-4cc5-9813-736405bdefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"Corpus\"\n",
    "model_dir = \"merged-fine-tuned\"\n",
    "device_map = {\"\": 0}\n",
    "device = \"cuda\"\n",
    "database_top_n_results = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a299a70-0e8f-4947-b8a5-af2b37a32bc3",
   "metadata": {},
   "source": [
    "## Load shared code\n",
    "This file defines the `ChatModel` and `Retrieval` classes used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0127f1-910c-49b6-9210-97d8b68ef671",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run shared_code.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde5370-9aa9-4138-8e0e-a52e17c0f6db",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a41d92-5a28-4668-8e8b-2f37bf0180e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e48b6a5d1594ff1883c92f3e04667f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "language_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10163ab3-e55c-403b-96f9-7d0d338cb18c",
   "metadata": {},
   "source": [
    "## Load the model into the ChatModel class from `shared_code.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064cd72c-2f70-49b6-8862-30d56ec9d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatModel(language_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c18cc-2fd8-46b5-a107-1d21c494187a",
   "metadata": {},
   "source": [
    "## Trying the model without access to the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551660eb-3f81-434e-8029-f0babd9b7969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To looping a gif, you need to use the following code:\n",
      "```python\n",
      "import pyautogui\n",
      "\n",
      "#initialize the global variable \"frame\" at 0\n",
      "frame = 0\n",
      "while True:\n",
      "    #get the current frame index from the gif\n",
      "    frame = frame + 1\n",
      "    #ensure that the frame index does not exceed the last frame of the gif (otherwise the program will crash)\n",
      "    if frame < len(img)):\n",
      "        #show the current frame in the gif\n",
      "        ia.imshow(img[frame])\n",
      "    elif frame >= len(img):\n",
      "        #restart the cycle by setting \"frame\" back to 0\n",
      "        frame = 0\n",
      "else:\n",
      "    #quit out of the script\n",
      "    pyautogui.event_setup()\n",
      "    quit()\n",
      "```\n",
      "This is an example using PyAutoGUI to open and show a png image repeatedly on screen for user interaction. The script first defines a variable called \"frame\", which is used as an index into the list img to access each frame of the gif. The while loop continues for eternity until it can be stopped by the user. In every iteration, the code checks whether this is the last frame of the gif by checking if frame is less than the length of img. If so, the code displays the corresponding frame and increments the indicator frame , before moving on to the next iteration with the incremental step \"frame += 1\". \n",
      "\n",
      "If your requirement was for repeating the gif continuously without any input from users or stopping automatically when no more frames are available, then all you need to do is replace the \"pyauto-gui.event_setup()\" line under the \"#quit out of the script\" comment with the relevant code snippet instead. \n",
      "\n",
      "Please let me know if there are further technical questions! 🤓 🎉👍⌛ ⏦️💚💰🏈🏆🏅💰🏒🌧️ 🎮🕹️💻🏫🏢️🔍🔍💣💥💥🔥🔥🔥‖🔥🔥🚀✯℉€😵......💭🗼🗿...🏤🏟♛🏐🏞😀🥳❤👩🏽👱️👰️👋💣💥💥💥💥💥💥🖺️🖴................. �������������������������������������������������������������������������anks���ank.....🥃🌊🌑🌕🌝🌟🌕💫🍸🏦🏦🏢🏢🏢🏢🏢🏢🏢🏢 distilled water💧💧💧🏥🏟🏢🏢🏢🏢🏢 distilled water🌫🌫🌥🌫🌞‖🌛🔥🌓🏟🌑🏞️🏞🏞🏢🏢🏢🏢 distilled water���������������ggi distilled water🌫🌫🌫🌫 distilled water🌫🌫🌫 distilled water🌫🌫 distilled water distilled water🌫 distilled water distilled water distilled water distilled water distilled water distilled water distilled water distilled water distilled water distilled water distilled water distilled water distilled water distilled water distilled water distilled water\n"
     ]
    }
   ],
   "source": [
    "chat_model.basic_chat(\"How do I loop a GIF?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035b376-3b51-4da9-a4fd-23f2a7d2f5fc",
   "metadata": {},
   "source": [
    "## Load the collection into the RetrievalAugmentedChat class from `shared_code.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7888382-4a37-4612-b7ef-3fa2a132d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rac = RetrievalAugmentedChat(\"db/\", collection_name, database_top_n_results, chat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8476ee89-d947-44e2-9c82-6797396cd3b2",
   "metadata": {},
   "source": [
    "## Run retrieval augmented chat\n",
    "Notice that the responses have switched from a general HTML/JavaScript context to include the document contents which provide examples of encoding the gif with ImageMagick so that it loops by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b0024a-5c2d-42bf-bbba-3533b3cf2fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Creating an animation from a series of images is straightforward using popular open source tools such as FFmpeg and libimagewidgets (libimagetoolkit), or professional commercial software such as Adobe Premiere Pro. However if you want to run through each frame step-by-step, you will need to write code to accomplish this. \n",
       "\n",
       "If you are thinking of doing this kind of animation and have any specific questions about how to do so please ask! For example, how many frames would you prefer to display (e.g. 300), what exactly are these frames showing, or where should they appear within the screen (e.g. centred)? Knowing more details before we begin may help us both figure out whether what you propose is viable, and what kind of features you might require to achieve this goal. Perhaps even giving me precise details could allow me to provide steps to reach this goal quickly! If however all you wish to know is \"how\" to achieve something, well... you still don’t specify this clearly enough! \n",
       "\n",
       "Alternatively, do you already have Animation Software you’re thinking of? What was its purpose when you bought it? Do you perhaps need assistance configuring said application? In which case please tell me more detail about your environment. Are you running Windows or Linux? Did you buy yourself a new computer just for this, or did you borrow it off somebody else? Maybe you have older computers lying around somewhere! Or maybe the machine you currently own isn’t powerful enough to run modern operating systems. Are there specific CPU requirements (or storage / memory availability) required for such software? Can you tell me these things now?! \n",
       "\n",
       "Perhaps you aren’t asking me what I would actually want to hear though… [ 🧐 ]\n",
       "\n",
       "So, do you really just not want me to give you tips so you can quickly learn what you need, or do you actually plan to do something with my advice? Please clarify what your ultimate goals are! Ask me followup questions until we get closer to them being achievable. Don’t merely say “yes” — describe why “yes”, describe how, prove it with examples, etc.. \n",
       "\n",
       "So let’s start simple then! Would you like to see a GIMP and XBMP style of SPLIT_VIDEO frame animation played back continuously inside a terminal? This software runs on virtually any common linux system! It uses the `curl` utility behind the scenes (but you only really need curl if your internet connection is slow!) It does have however been noticed that sometimes having an Internet available is helpful ;) \n",
       "\n",
       "With `curl`, it creates a series of files called .CUR files; each of which contains a single image frame extracted from one of the PNG frames of the original video. A program called \"openpnmv\", which uses the Perplexity PNMV image format, allows us to cycle between these .CUR frames at regular intervals. All we need do is run the following commands! Here’s how I would do it on Ubuntu, although the process is very general and can work anywhere:\n",
       "\n",
       "```\n",
       "wget http://yourvideourl.com/someframe.png # downloads someframe.png\n",
       "convert someth**=*.png 1x 480x256 # converts something to a single frame\n",
       "curl ffmpeg-hvfllip https://pub.lukefrisker.nix.filesystem/splithorizentropy-0x3a9bdaeaeeafea50498aea79afebae3bea4ec7bacefd4aab5ba2a4fba4e856a8c4babd7cf9c3cad2c8a5406ee95b4b6236b87a7e2dfa\n",
       "``` \n",
       "\n",
       "You can also modify the timing interval between frames, add text to each frame, maybe play around with other options, etc. All described by the manual page for “openpmnv”. Maybe you wanted another suggestion of my style? \n",
       "\n",
       "Now, you can enjoy your first self-hosted animation playing infinitely in a terminal window! Why would you ever stop making animations anyway?! The world needs more animations! \n",
       "\n",
       "Possibly you had asked a genuine question about how you implement these sorts of things in real world applications though. May we continue this conversation sometime later then? Or perhaps while we wait I can answer more basic queries about the underlying concepts or other ways to achieve this kind of dynamic content? [ ⏎ ]\n",
       "\n",
       "\n",
       "\n",
       " **Reference documents:** \n",
       "\n",
       "* [corpus/imagemagick/set-a-gif-to-loop.md](corpus/imagemagick/set-a-gif-to-loop.md) distance: 0.97\n",
       "* [corpus/imagemagick/compress-animated-gif.md](corpus/imagemagick/compress-animated-gif.md) distance: 1.28\n",
       "\n",
       "**Inference time in seconds 20.4060**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rac.markdown_chat(\"How do I loop a GIF?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd178ea-8f8d-4a0f-a4ce-9bcde8dffd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, you can use Node Package Manager tools such as **npx** or **yarn** with GitHub Actions by taking advantage of the **exec** Trigger and its associated command line scripts feature. Here's an example script that demonstrates how you might do this:\n",
       "\n",
       "```\n",
       "in main.json\n",
       "...\n",
       "{\n",
       "    \"env/bin\": [\"npx start <file>.json\"],\n",
       "}\n",
       "or\n",
       "in main.sh:\n",
       "...\n",
       "git-origin # Start git server in background\n",
       "./run-local.sh # Open local development environment\n",
       "}\n",
       "```\n",
       "where `<file>`.json` refers to your favorite NodeJS framework or developer workstation, perhaps **Node**. The script starts the GitHub server, opens an interactive local development environment,\n",
       "opens the local configuration editor (usually `~/.viscode/vscode`) and offers options for both starting the project and executing your favourite Node or JavaScript runtime respectively. If you're not keen on complicated installations, simpler shell-based alternatives may suit you better too.\n",
       "\n",
       "When using the **exec** trigger's built-in terminal app to launch Node apps, there should be few restrictions about the actual `npx` or `yarn` commands you wish to run inside of any given repository; if you believe any restriction does exist beforehand you may wish to ask or confirm this through discussion with @leagueterrace.\n",
       "\n",
       "If this approach suits your purposes well, you may also wish to take into account some security considerations about running external code, especially when your Actions code maintains its own Terminal application (for your convenience), inside of the GitHub Actions workflow, which can be utilized by users including people who may wish to attack or evade some of these security mechanisms. You may wish to read relevant GitHub guidelines on the subject, GitHub Security Policy Docs · GitHub Developer Guides · Guidelines for working with external services using GitHub API v06_03_02 || 9a62fb6ca1cba8dfdad481cc332ebcceeaabae962af13ee6bb6a93ad79e73a23a03d1c0ea3d87b89e8bfa18eb6e7c2df8e6f6ae963b2cad5311b3bc6d2f1396e7b3aaa5fc9c0f6ecfe4fbe50e4d0b2b27f43246400456de4db975b48a6d9f2d4d6cb733f0d92a835f69e992427ea2f5e436b261871363dcedd33753ef6d3308d76c534a3bf5539e636960afc6cf0ccf05dd5eb1b69b295c77dece80ed80afe76ce634b3af3e2ef0e538a9269d67ebfe06a8bc54b96d689a0b9ec7e74c3e746ea3e6c3d0a0a3150e6b7d582f0f79d59631344a1361991d9d3564436b693b3d363f3cd93d36ef8ae8210ece9c5d3d6d3b63d6d3357b38d3f3d6df33c03e63b0969b5b67bd5fdfa77ddeb0d4d65b6b13ec9e6b6b37e6b6b6df65dfc430d6dfca0dfdc06dca7cfa9a9e545463b345463b3a2ff9afe1b03ee63ab67bf65dfed93dfd0f26563b3ff\n",
       "\n",
       " **Reference documents:** \n",
       "\n",
       "* [corpus/github-actions/npm-cache-with-npx-no-package.md](corpus/github-actions/npm-cache-with-npx-no-package.md) distance: 0.88\n",
       "* [corpus/github-actions/attach-generated-file-to-release.md](corpus/github-actions/attach-generated-file-to-release.md) distance: 1.11\n",
       "\n",
       "**Inference time in seconds 20.2607**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rac.markdown_chat(\"Can I use npx with GitHub actions?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3ed6c-25c5-43b4-a3fb-b7dc52dba8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
